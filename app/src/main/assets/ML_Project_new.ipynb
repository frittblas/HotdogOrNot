{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EalIc4lE2Bk"
   },
   "source": [
    "Hotdog or Not\n",
    "By: Hans, Adam, Fredrik och Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1698834657626,
     "user": {
      "displayName": "Robin Cobanov",
      "userId": "00479066852093318316"
     },
     "user_tz": -60
    },
    "id": "obG5RzuxV526",
    "outputId": "3d64accc-051a-4c66-de72-9b19a907c12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1501.jpg', '1502.jpg', '1503.jpg', '1504.jpg', '1505.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "extracted_files = os.listdir('hotdog-nothotdog/test/hotdog/')\n",
    "print(extracted_files[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1698834952728,
     "user": {
      "displayName": "Robin Cobanov",
      "userId": "00479066852093318316"
     },
     "user_tz": -60
    },
    "id": "fCKOHWK9Wum3",
    "outputId": "617c25ce-a3ae-4745-afa6-2b518a3bce5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 644 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values to [0, 1]\n",
    ")\n",
    "\n",
    "# Set the path to the directory containing your images\n",
    "path_train_hotdog = 'hotdog-nothotdog/train/'\n",
    "path_test_hotdog = 'hotdog-nothotdog/test/'\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    path_train_hotdog,\n",
    "    target_size = (150,150),\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    path_test_hotdog,\n",
    "    target_size = (150,150),\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "94/94 [==============================] - 24s 249ms/step - loss: 0.6878 - accuracy: 0.5890 - val_loss: 0.6323 - val_accuracy: 0.6630\n",
      "Epoch 2/6\n",
      "94/94 [==============================] - 24s 255ms/step - loss: 0.5874 - accuracy: 0.7010 - val_loss: 0.6174 - val_accuracy: 0.6693\n",
      "Epoch 3/6\n",
      "94/94 [==============================] - 24s 258ms/step - loss: 0.5683 - accuracy: 0.7027 - val_loss: 0.6443 - val_accuracy: 0.6708\n",
      "Epoch 4/6\n",
      "94/94 [==============================] - 23s 249ms/step - loss: 0.5443 - accuracy: 0.7260 - val_loss: 0.5820 - val_accuracy: 0.7096\n",
      "Epoch 5/6\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.5112 - accuracy: 0.7520 - val_loss: 0.6132 - val_accuracy: 0.6755\n",
      "Epoch 6/6\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.4487 - accuracy: 0.7883 - val_loss: 0.5700 - val_accuracy: 0.7252\n",
      "21/21 [==============================] - 2s 69ms/step - loss: 0.5700 - accuracy: 0.7252\n",
      "Test accuracy: 72.52%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#\n",
    "'''\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience= 5,          \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "history = model.fit(train_data, epochs=20, validation_data=test_data, callbacks=[early_stopping])\n",
    "'''\n",
    "#\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, epochs=6, validation_data=test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-72.52.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "It's a hot dog!\n",
      "[[0.3781513]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load an image for classification\n",
    "image_path = 'hotdog-nothotdog/test/hotdog/1731.jpg'  # Replace with the actual path\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction using the trained model\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Interpret the prediction\n",
    "if prediction < 0.5:\n",
    "    print(\"It's a hot dog!\")\n",
    "else:\n",
    "    print(\"It's not a hot dog!\")\n",
    "    \n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\fritt\\AppData\\Local\\Temp\\tmpxp_vpdu4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\fritt\\AppData\\Local\\Temp\\tmpxp_vpdu4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TFLite ModelAnalyzer ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the CONV_2D op takes\n",
      "tensor #0 and tensor #4 and tensor #1 as input and produces tensor #12 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#21]\n",
      "  Op#0 CONV_2D(T#0, T#4[], T#1[]) -> [T#12]\n",
      "  Op#1 MAX_POOL_2D(T#12) -> [T#13]\n",
      "  Op#2 CONV_2D(T#13, T#5[], T#2[]) -> [T#14]\n",
      "  Op#3 MAX_POOL_2D(T#14) -> [T#15]\n",
      "  Op#4 CONV_2D(T#15, T#6[], T#3[]) -> [T#16]\n",
      "  Op#5 MAX_POOL_2D(T#16) -> [T#17]\n",
      "  Op#6 RESHAPE(T#17, T#9[-1, 36992]) -> [T#18]\n",
      "  Op#7 FULLY_CONNECTED(T#18, T#10[], T#8[]) -> [T#19]\n",
      "  Op#8 FULLY_CONNECTED(T#19, T#11[], T#7[]) -> [T#20]\n",
      "  Op#9 LOGISTIC(T#20) -> [T#21]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_conv2d_9_input:0) shape_signature:[-1, 150, 150, 3], type:FLOAT32\n",
      "  T#1(sequential_3/conv2d_9/BiasAdd/ReadVariableOp) shape:[32], type:FLOAT32 RO 128 bytes, data:[]\n",
      "  T#2(sequential_3/conv2d_10/BiasAdd/ReadVariableOp) shape:[64], type:FLOAT32 RO 256 bytes, data:[]\n",
      "  T#3(sequential_3/conv2d_11/BiasAdd/ReadVariableOp) shape:[128], type:FLOAT32 RO 512 bytes, data:[]\n",
      "  T#4(sequential_3/conv2d_9/Conv2D) shape:[32, 3, 3, 3], type:FLOAT32 RO 3456 bytes, data:[]\n",
      "  T#5(sequential_3/conv2d_10/Conv2D) shape:[64, 3, 3, 32], type:FLOAT32 RO 73728 bytes, data:[]\n",
      "  T#6(sequential_3/conv2d_11/Conv2D) shape:[128, 3, 3, 64], type:FLOAT32 RO 294912 bytes, data:[]\n",
      "  T#7(sequential_3/dense_7/BiasAdd/ReadVariableOp) shape:[1], type:FLOAT32 RO 4 bytes, data:[]\n",
      "  T#8(sequential_3/dense_6/BiasAdd/ReadVariableOp) shape:[128], type:FLOAT32 RO 512 bytes, data:[]\n",
      "  T#9(sequential_3/flatten_3/Const) shape:[2], type:INT32 RO 8 bytes, data:[-1, 36992]\n",
      "  T#10(sequential_3/dense_6/MatMul) shape:[128, 36992], type:FLOAT32 RO 18939904 bytes, data:[]\n",
      "  T#11(sequential_3/dense_7/MatMul) shape:[1, 128], type:FLOAT32 RO 512 bytes, data:[]\n",
      "  T#12(sequential_3/conv2d_9/Relu;sequential_3/conv2d_9/BiasAdd;sequential_3/conv2d_9/Conv2D;sequential_3/conv2d_9/BiasAdd/ReadVariableOp) shape_signature:[-1, 148, 148, 32], type:FLOAT32\n",
      "  T#13(sequential_3/max_pooling2d_9/MaxPool) shape_signature:[-1, 74, 74, 32], type:FLOAT32\n",
      "  T#14(sequential_3/conv2d_10/Relu;sequential_3/conv2d_10/BiasAdd;sequential_3/conv2d_10/Conv2D;sequential_3/conv2d_10/BiasAdd/ReadVariableOp) shape_signature:[-1, 72, 72, 64], type:FLOAT32\n",
      "  T#15(sequential_3/max_pooling2d_10/MaxPool) shape_signature:[-1, 36, 36, 64], type:FLOAT32\n",
      "  T#16(sequential_3/conv2d_11/Relu;sequential_3/conv2d_11/BiasAdd;sequential_3/conv2d_11/Conv2D;sequential_3/conv2d_11/BiasAdd/ReadVariableOp) shape_signature:[-1, 34, 34, 128], type:FLOAT32\n",
      "  T#17(sequential_3/max_pooling2d_11/MaxPool) shape_signature:[-1, 17, 17, 128], type:FLOAT32\n",
      "  T#18(sequential_3/flatten_3/Reshape) shape_signature:[-1, 36992], type:FLOAT32\n",
      "  T#19(sequential_3/dense_6/MatMul;sequential_3/dense_6/Relu;sequential_3/dense_6/BiasAdd) shape_signature:[-1, 128], type:FLOAT32\n",
      "  T#20(sequential_3/dense_7/MatMul;sequential_3/dense_7/BiasAdd) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#21(StatefulPartitionedCall:0) shape_signature:[-1, 1], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'conv2d_9_input' : T#0\n",
      "- Outputs: \n",
      "    'dense_7' : T#21\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   19318096 bytes\n",
      "    Non-data buffer size:       4064 bytes (00.02 %)\n",
      "  Total data buffer size:   19314032 bytes (99.98 %)\n",
      "    (Zero value buffers):          0 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "keras_model = tf.keras.models.load_model('model-72-52.h5')\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a .tflite file\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "    \n",
    "tf.lite.experimental.Analyzer.analyze(model_content=tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb",
     "timestamp": 1697804386421
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
